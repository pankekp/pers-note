# MySQL 并发

---

## 1. 事务

**原子性**（Atomicity）：事务是不可分割的最小单元。
**一致性**（Consistency）：数据库数据在事务执行前后保持一致。
**隔离性**（Isolation）：一个事务所做的修改在未提交前对其他事务不可见。
**持久性**（Durability）：事务一旦提交，其所做的修改会永久保存在数据库中。

如何理解事务的 ACID 特性：

* 只有满足一致性，事务的执行结果才是正确的
* 无并发时，只需要满足原子性就一定能保证一致性，因为此时默认的串行执行就可以保证隔离性
* **有并发时，需要同时满足隔离性与原子性才行**
* 事务的持久性是为了应对数据库崩溃的状况

## 2. 并发问题

### 2.1 隔离性与并发的取舍

存在并发时需要同时满足隔离性和原子性：

* 事务可以保证操作是原子性的
* 要保证隔离性，最直接的是一个事务在访问数据时，令其他要対这些数据操作的事务进行排队，多个事务呈现串行化执行

可见串行化和事务可以保证并发操作时不会出现一致性问题，但是串行化过于影响性能，所以**舍弃一部分隔离性来提高并发性**。

### 2.2 并发问题与隔离性的体现

牺牲一部分隔离性后，并发事务访问数据就会出现多种问题，主要有以下三种情况：

并发读：读操作不会影响记录，所以允许这种情况发生。

并发写：多个事务対同一记录进行写操作时会出现丢失更新的问题。

* **第二类丢失更新**：一个事务的更新覆盖了另一个事务提交的更新
  | T1（写）      | T2（写）      |                                   |
  | ------------- | ------------- | --------------------------------- |
  | BEGIN         |               |
  |               | BEGIN         |
  | 查询余额 1000 |               |
  |               | 查询余额 1000 |
  |               | 转入 100      |
  |               | COMMIT        |
  | 转出 100      |               |
  | COMMIT        |               | T1 的转出操作覆盖了 T2 的转入操作 |
* **第一类丢失更新**：一个事务的更新覆盖了另一个事务提交的更新，并且进行了回滚，则两次更新操作都丢失了
  | T1（写）      | T2（写）      |                                                                             |
  | ------------- | ------------- | --------------------------------------------------------------------------- |
  | BEGIN         |               |
  |               | BEGIN         |
  | 查询余额 1000 |               |
  |               | 查询余额 1000 |
  |               | 转入 100      |
  |               | COMMIT        |
  | 转出 100      |               |
  | COMMIT        |               |
  | ROLLBACK      |               | T1 的转出操作覆盖了 T2 的转入操作，并且 T1 的回滚操作又覆盖了 T1 的转出操作 |

并发读写：一个事务读一个事务写，这时会出现脏读、不可重复读、幻读。

* **脏读**：一个事务读到了另一个事务回滚前的脏数据
  | T1（写）             | T2（读）     |                           |
  | -------------------- | ------------ | ------------------------- |
  | BEGIN                |              |
  |                      | BEGIN        |
  | 更新余额 1000 -> 900 |              |
  |                      | 查询余额 900 |
  |                      | COMMIT       |
  | ROLLBACK             |              | T2 读到了不存在的余额 900 |

* **不可重复读**：一个事务读到了另一个事务已提交的新数据
  | T1（写） | T2（读）      |                                            |
  | -------- | ------------- | ------------------------------------------ |
  | BEGIN    | BEGIN         |
  |          | 查询余额 1000 |
  | 转出 100 |               |
  | COMMIT   |               |
  |          | 查询余额 900  | 同一个事务 T2 中两次対余额的查询发生了变化 |

* **幻读**：一个事务再次进行**相同**的查询时读到了另一个事务已提交的新插入的数据
  | T1（写）   | T2（读）              |                                                   |
  | ---------- | --------------------- | ------------------------------------------------- |
  | BEGIN      | BEGIN                 |
  |            | SELECT *（1000 rows） |
  | 插入新用户 |                       |
  | COMMIT     |                       |
  |            | SELECT *（1001 rows） | T2 中第二次対相同范围的查询查出了第一次没有的记录 |

针对不同的并发问题，SQL 标准规定了不同的事务隔离级别，不同的隔离级别下解决了不同的并发问题。**事务的隔离级别就是在不同程度下舍弃隔离性从而提升并发的具体表现**：

|                  | 脏读 | 不可重复读 | 幻读 |
| ---------------- | ---- | ---------- | ---- |
| READ UNCOMMITTED | no   | no         | no   |
| READ COMMITTED   | yes  | no         | no   |
| REPEATABLE READ  | yes  | yes        | no   |
| SERIALIZABLE     | yes  | yes        | yes  |

需要注意的几点：

* MySQL 的默认隔离级别为 RR
* 并发写问题（丢失更新）在任何一种隔离级别下都不允许发生
* **不同的数据库対 SQL 标准规定的隔离级别的实现不同，比如 MySQL 在 REPEATABLE READ 下就可以避免幻读**
* 串行化可以避免所有问题，这也对应了之前所说的：串行化和事务可以保证并发操作时不会出现一致性问题

## 3. 并发问题在不同隔离级别下是如何解决的

根据前文叙述，需要解决的并发问题分为并发写和并发读写。

### 3.1 并发写

并发写会产生丢失更新这种严重问题，所以任何隔离级别下都不允许发生，避免的方式就是在多个未提交的事务并发写同一记录时，令它们排队执行，排队的过程通过加锁来实现。

### 3.2 并发读写

显然如果并发读写也通过加锁的方式来串行化执行是不会产生并发问题的，但是会降低并发度，所以 MySQL 中的 InnoDB 通过 MVCC 来解决并发读写的问题。

**MVCC 的作用就是令读写操作可以不用加锁地并发执行，避免了并发问题，提高了并发度，并在此基础之上实现了不同的隔离级别**。

#### 3.2.1 MVCC 的基础：版本链

对于 InnoDB 来说，聚簇索引数据页的记录中包含两个隐藏列：

* trx_id：操作记录的事务 id。只有写操作（UPDATE、INSERT、DEELTE）才会被分配 trx_id，而读操作默认为 0
* roll_pointer：修改记录时，旧版本的记录会被写入 undo log 中，这个字段指向 undo log 中的旧版本记录

**每次修改都会将旧版本的这条记录写入 undo log，多次修改后这些记录组成了由 roll_pointer 连接的版本链，而链表头就是最新的记录**。

#### 3.2.2 MVCC 的实现：ReadView

为了实现不同的隔离级别，MVCC 的核心问题就是**判断当前事务应该读取记录版本链中哪个版本的数据**，InnoDB 中借助 ReadView 来解决这个问题：

> 在 RC 和 RR 下，SELECT 会触发 ReadView 的生成。

* m_ids：生成时活跃的（还未提交的）事务 id
* min_trx_id：生成时活跃的最小事务 id
* max_trx_id：生成时应该分配个下一个事务的 id。由于事务 id 是递增分配的，所以这个值不一定是 MAX(m_ids)，与已经提交的事务 的 id 也有关
* creator_trx_id：生成该 ReadView 的事务 id

SELECT 时记录的版本可见性判断的规则如下：

* trx_id == creator_trx_id：当前事务在访问自己修改过的记录，可访问
* trx_id < min_trx_id：操作这个版本的记录的事务在当前事务生成 ReadView 前已经被提交，可访问
* trx_id > max_trx_id：操作这个版本的记录的事务在当前事务生成 ReadView 后才开始，不可访问
* min_trx_id <= trx_id <= max_trx_id：
  * 如果 trx_id 属于 m_ids，也就是说操作这个版本的记录的事务在当前事务生成 ReadView 时还是活跃的，不可访问
  * 否则说明操作这个版本的记录的事务在当前事务生成 ReadView 时已经提交，可访问
* 如果不可访问则顺着版本链继续查找下一个版本，再次进行判断

**RC 的实现**：一个事务中每次 SELECT 时都会成一个新的 ReadView，对于未提交的事务，trx_id 满足 min_trx_id <= trx_id <= max_trx_id 并且属于 m_ids，根据版本可见性规则，这个版本数据对其他事务不可见，避免了脏读。

**RR 的实现**：一个事务中只有第一次 SELECT 时会生成 ReadView，之后都是复用之前的，从而避免了不可重复读和幻读（**这里的幻读指前文中举例的 select 导致的幻读，而对于 insert / update 导致的幻读无法避免**）。

**RU**：RU 下脏读、不可重复读、幻读都不可避免，而这三种问题其实都反映了同一个现象：读取到了最新的（未提交的事务修改的）数据，対应到 MVCC 中，直接读取版本链链表头的最新记录即可。

**串行化**：MVCC 无法实现，InnoDB 采用加锁的方式来保证串行化。

需要明确的是，不管是一个事务读另一个事务正在写的记录，还是一个事务写另一个事务正在读的记录，写操作的对象是版本链上处于头节点的最新版本，而读操作读取的是历史版本，这种方式在 RU、RC、RR 下都不会产生矛盾。

## 4. 锁

首先需要明确的是：

* **锁是除了 MVCC 之外另一种解决并发问题的方式**，有些场景下如果既不能读取正在被操作的记录，也不允许读取旧版本，那么就需要対读写操作加锁来同步执行顺序
* MVCC 中的读操作（SELECT）称为一致性读 / 快照读，也就是说不会在读数据时加锁，读取的数据不是最新版本，所以 MVCC 的读写操作才不会发生冲突，可以避免 SELECT 导致的幻读
* 如果使用加锁的 SELECT 则会读到最新的数据，导致各种并发读写问题

### 4.1 读写锁

|                   | 读锁（Shared） | 写锁（Exclusive） |
| ----------------- | -------------- | ----------------- |
| 读锁（Shared）    | 兼容           | 不兼容            |
| 写锁（Exclusive） | 不兼容         | 不兼容            |

### 4.2 封锁协议

封锁协议就是使用读写锁来避免并发问题的一系列规则，从而体现出不同的隔离级别。

**一级封锁协议（RU）**：写数据之前加写锁，直到事务结束才释放。

* 过程中其他事务无法写此数据，可防止丢失更新。其中事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）
* 在一级封锁协议中，如果仅仅是读数据而不对其进行修改，是不需要加读锁的，所以会产生脏读和不可重复读

**二级封锁协议（RC）**：在一级封锁协议的基础上，读其他事务正在写的数据之前加读锁，读完立刻释放锁。

* 由于读完后立即释放读锁，而不是等到整个事务结束，所以其他事务仍旧有可能加写锁并修改数据，再次读会发现数据变化，发生了不可重复读

**三级封锁协议（RR）**：与二级封锁协议不同的是将读锁从读完立即释放变为了事务结束再释放，防止了不可重复读，但无法避免幻读。

**两段锁协议（S）**：将事务分成两个阶段，加锁阶段和解锁阶段

* 扩展阶段：在对任何数据进行读、写操作之前，首先要申请并获得该数据的锁
* 收缩阶段：在释放一个锁之后，事务不再申请和获得其他锁

事务遵守两段锁协议是串行化的充分条件，所以能够避免幻读，但不是必要条件。

### 4.3 锁的粒度

锁可以対单独的行或者整张表进行作用，读写锁就可以対行和表进行加锁，兼容的锁可以穿透表锁到达行锁，如加了表锁 S，则可以继续加表锁 S，也可以加行锁 S，而排斥所有写锁。

但是如果想加表锁 X，则需要判读每一行是否有锁，为了避免这种遍历，引入意向锁（Intention Locks）。意向锁属于表锁，可以快速判断表记录中是否存在行锁，省去了判断每一行的过程。

### 4.4 悲观锁与乐观锁

**悲观锁**：认为数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改是大概率的，因此在整个数据处理过程中，将数据处于锁定状态。

**乐观锁**：大多是基于数据版本记录机制实现，如 MVCC。

### 4.5  InnoDB 中的锁

#### 4.5.1 表锁

不使用索引时自动加表锁，因为 InnoDB 的行锁是通过给索引加锁实现的，如果不通过索引条件检索数据，那么 InnoDB 查找记录就需要扫描全表，要扫描全表，就需要锁定表。

#### 4.5.2 行锁

**Record Lock**：

* SELECT 读锁：

  ```sql
  select ... lock in share mode
  ```

* SELECT 写锁：

  ```sql
  select ... for update
  ```

* DELETE、UPDATE 会默认加写锁，INSERT 默认加隐式锁，所以 MVCC 无法避免 INSERT 和 UPDATE 导致的幻读，需要间隙锁配合

**Gap Lock**：

**间隙锁的提出仅仅是为了防止插入幻影记录**。

单凭记录锁无法解决幻读，因为第一次查询时幻影记录还未插入，无法给他们加锁，所以引入间隙锁：

* 当其他事务执行 INSERT 时，如果即将插入的间隙存在间隙锁，则本次 INSERT 会被阻塞，直到持有间隙锁的事务提交
* 索引数据页存在 Supremum 记录，表示该⻚面中最大的记录，给它加间隙锁可以锁定记录后的间隙
* 如果使用的是没有索引的字段，那么会给全表加入间隙锁。因为没有索引，则这些字段也就无法排序，不存在区间，除非该事务提交，否则其它事务无法插入任何数据

**Next-Key Lock**：间隙锁和记录锁的结合。

**隐式锁**：

如果一个事务新插入一条记录，这条记录没有关联任何锁，会出现并发问题：

* 使用加锁的 SELECT 会出现并发读问题
* 修改这条记录会出现丢失更新

所以事务会对新插入的记录不显式地加锁，防止上述情况发生。

### 4.6 MyISAM 中的锁

MyISAM 不支持行锁，执行 SQL 时自动加表锁，SELECT 加读锁，UPDATE、INSERT、DELETE 加写锁。
